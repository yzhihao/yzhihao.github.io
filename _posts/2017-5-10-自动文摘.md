---
layout: post
title:  自动文摘
desc: 我的博客
keywords: 'blog,Machine Learning,AI'
date: 2017-5-10T00:00:00.000Z
categories:
  - Machine Learning
tags:
  - Machine Learning
  - AI
icon: fa-book
---


## 目录
**欢迎在文章下方评论，建议用电脑看**

* 目录
{:toc}


# 自动文摘

## 自动文摘分类


自动文摘的方法主要分为两大类，extractive和abstractive。前者是目前最主流、应用最多、最容易的方法，后者相对来说更有一种真正人工智能的味道。还有另外一种分类方法是，单文档摘要和多文档摘要，前者是后者的基础，但后者不只是前者结果简单叠加那么简单。

## Extractive Summarization

抽取式的方法基于一个假设，一篇文档的核心思想可以用文档中的某一句或几句话来概括。那么摘要的任务就变成了找到文档中最重要的几句话，也就是**一个排序的问题**。它主要是排序的问题，输出的是排序后的结果。**因为各个句子都是从不同的段落中选择出来的，如果只是生硬地连起来生成摘要的话，很难保证句子之间的衔接和连贯。保证可读性是一件很难的事情。**

>由于研究的方向是人工智能，所以对于这个方式不多研究！


## Abstractive


主要包含的难点是：

1、理解文档。所谓理解，和人类阅读一篇文章一样，可以**说明白文档的中心思想，涉及到的话题**等等。

2、**可读性强**。可读性是指生成的摘要要能够连贯（Coherence）与衔接（Cohesion），通俗地讲就是人类读起来几乎感觉不出来是AI生成的（通过图灵测试）。

3、简练总结。在理解了文档意思的基础上，提炼出最核心的部分，用**最短的话讲明白全文的意思。**

近几年随着Deep Learning的火爆，研究者们利用一些最新的研究成果来做summarization，比如attention model，比如rnn encoder-decoder框架，在一定程度上实现了abstractive，但还是处于研究初期，效果还不算很好。

## Evaluation

自动文摘最大的一个难点是评价问题，如何有效地、合理地评价一篇文摘的效果是一个很难的问题。

一个是人工评价，这个的误差度比较高，时间成本又高，效率又太低了。所以一般都不适合。

另一个是自动评价，计算机评价效果，需要给定参考摘要作为标准答案，通过制定一些规则来给生成的摘要打分。现有的评价标准存在的一个重要问题在于没有考虑语义层面上的相似，评价extractive还好，但评价abstractive就会效果不好了。在词、句子甚至段落这个层面上的表示学习研究的非常多，也有很多的state-of-the-art的结果，所以做语义层面上的评价并不难。

## abstractive summarization细节

abstractive是学术界研究的热点，尤其是Machine Translation中的encoder-decoder框架和attention mechanism十分火热，大家都试着将abstractive问题转换为sequence-2-sequence问题，套用上面两种技术，得到state-of-the-art结果，2015年来已经有许多篇paper都是这种套路，于是就有了下面的吐槽：

<img src="{{ site.img_path }}/Machine Learning/abstractive_summarization.png" alt="header1" style="height:auto!important;width:auto%;max-width:1020px;"/>

## Neural Summarization

涉及到Encoder-Decoder框架和Attention机制的博文请看[这篇]()

使用deep learning技术来做abstractive summarization的paper屈指可数，大体的思路也类似，大概如下：

0、首先将自动文摘的问题构造成一个seq2seq问题，通常的做法是将某段文本的first sentence作为输入，headlines作为输出，本质上变成了一个headlines generative问题。

1、选择一个big corpus作为训练、测试集。自动文摘的技术没有太成熟的一个重要原因在于没有一个成熟的大规模语料。一般来说都选择Gigawords作为训练、测试集，然后用DUC的数据集进行验证和对比。

2、选择一个合适的encoder，这里可以选simple rnn，lstm rnn，gru rnn，simple birnn，lstm birnn，gru birnn，deep rnn，cnn，以及各种各样的cnn。不同model之间的组合都是一种创新，只不过创新意义不太大。用encoder将输入文本表示成一个向量。

3、选择一个合适的decoder，decoder的作用是一个language model，用来生成summary words。

4、设计一个合适的attention model。不仅仅基于encoder last hidden state vector和上文来预测输出文本序列，更要基于输入中“注意力”更高的词来预测相应的词。

5、设计一个copy net。只要是语言模型都会存在相同的问题，比如out-of-vocabulary词的处理，尤其是做新闻类摘要的生成时，很多词都是人名、机构名等专有名词，所以这里需要用copy net 将输入中的词copy过来生成输出。在生成中文摘要问题上，将words降维到characters可以避免oov的问题，并且取得不错的结果。







